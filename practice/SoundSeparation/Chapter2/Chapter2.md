# 音声処理の基礎
## 音声ファイルを開く
- 音声波形とは、時間ごとの音圧信号である。
- この音圧信号を一定時間記録したものが音声ファイルである。
- 音声ファイルは２種類ある
  - 元の音声波形を圧縮して保存するもの
  - 無圧縮のもの(PCM方式：サンプリング周波数にしたがって、一定間隔で測定した音声信号が所定のビット数で記録されている)
- サンプリング周波数とは １秒間に音圧を何回サンプリングしたかである。(ex.サンプリング周波数が16,000Hzであれば、一秒あたり16,000このデータが入っている)
- サンプル数は音声ファイル全体のサンプルサイズ
- サンプル数をサンプリング周波数で割れば何秒のデータであるかを知ることができる
- チャンネル数は、音声ファイルが何本のマイクロホンで収録されたかを示している
- 音声波形において、信号の統計的性質が時間ごとに大きく変化する信号を**非定常**な信号という。逆に大きく変化しな信号を**定常**な信号という
  - 音声は母音(声帯振動が起きている)は定常な信号と考えられる 。子音の場合は摩擦音などは定常と捉えられるが、クリック音などは非定常
  - 修士になった数式で判断できるように


## 時間周波数領域への変換
- 同じ周波数で、同じ振幅だとしても、波形のピークが時間軸のどこにくるかで、波形の形状は変わる。時間軸方向で波形が前後にずれる量を**位相**と呼ぶ
  - (振幅や周波数については意識していたが、位相についてはあまり意識していなかった)(音声において位相はあまり気にしない。反響では速度が重要なので位相を気にする。)
- サンプリング定理について
  - 音声データは一定の間隔で離散的に記録されたデータである(離散:連続ではないとびとびの値)
  - サンプリング周波数Fsの半分Fs/2より上の周波数成分は、サンプリングされた音声データから元々の連続的な波形を正しく復元することができない(サンプリング周波数が16,00Hzの時8,000Hz以上の音は波形にはならず直線的なグラフになってしまう)
  - この上限周波数のことを**ナイキスト周波数**という
  - 音声データを録音する時にはナイキスト周波数より高い周波数の音が混ざらないように注意してサンプリングしなければならない
    - 高い周波数の音には何があるのか?
    - 人の声の周波数はいくつか?人の声において収録できない周波数の影響はあるのか?
    - 現状できる最も高いサンプリング周波数は?A.原理上いくらでもできる  高ければ高いほど誤差に弱い
  - 低域通過フィルタを掛けて対処する
- 音声データの中に含まれる角周波数成分の振幅と位相のを調べる方法を周波数解析という
- 時系列のデータをデータを各周波数の振幅と位相にのデータに変換する方法を**フーリエ変換という**
  - 変換したデータは離散なのか?
  - 各周波数の数値はどのように分けられているのか? 
- フーリエ変換は時系列のデータを時間軸を持たない周波数領域の信号に変換
  - 最初から最後でまとめて、一括でフーリエ変換してしまうと、(「あ・い・う・え・お」のどの周波数が「あ」の音なのかわからなくなってしまう)
- そこで、音声データを区切り、フーリエ変換することを **短時間フーリエ変換(STFT:Short Term Fourier Transform)** という(「あ・い・う・え・お」の「あ」と「い」で区切って「あ」のみの周波数を得ることができる)
  - 短時間の時系列のデータ一つひとつを**フレーム**という
  - 各フレームの時間幅を**フレームサイズ**という
  - 各フレームの中では時間軸はなくなるが、各フレームを時間方向に並べることで、周波数の変化を見ることができる
  - 音声の振幅が一定であると考えられる数十ミリ秒単位でSTFTを実行
  - 各フレームはオーバーラップさせてSTFTする(フレームサイズの1/2や3/4程度オーバーラップさせるのが一般的)
  - 位相は考慮されているのか?
  - 時間軸はなくなるということは、日本語は母音と子音が組み合わさっているため一文字ごとに区切ると良くない?そもそも一字よりも細かい単位で短時間フーリエ変換されているのか?
- STFTを行い音声波形をフレームごとに切り出すときに、窓関数という関数をその波形に掛ける。よく使われるものはハニング窓(hanning)とハミング窓が(hamming)ある
  - 他の周波数が漏れ込む影響を軽減できる
    - なんで?Aフーリエ変換は定常な信号のみ、短く切ったものが連続していると考える。
-  

